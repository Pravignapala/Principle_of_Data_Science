{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pravignapala/Principle_of_Data_Science/blob/main/ProjectPDS1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs7Vwte5vGyf",
        "outputId": "7b342dec-900c-45eb-adbc-bb882ea91bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seo1LIdbhMXA",
        "outputId": "0f1bddb6-946d-4bf3-98ed-7333810163fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year                                              title  \\\n",
            "0  1920  At last the Federal Reserve Board has issued r...   \n",
            "1  1920                            WILL TEST DOOR SERVICE.   \n",
            "2  1920                    Sanction for Chinese Contracts.   \n",
            "3  1920                            LEADS FRAZIER BY 4,496.   \n",
            "4  1920  CHICAGO, April 30.--With 300 suspicious charac...   \n",
            "\n",
            "                                             excerpt  \n",
            "0                                                     \n",
            "1  Service Board to Further Examine I.R.T. Safety...  \n",
            "2                                                     \n",
            "3  Langer's Margin Falls in North Dakota--Gronna ...  \n",
            "4  Federal Agents and Police Round-- up Suspiciou...  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming nyt_data.parquet is in your Google Drive's MyDrive folder\n",
        "df = pd.read_parquet('/content/drive/MyDrive/nyt_data.parquet')\n",
        "\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you want to display the DataFrame's info\n",
        "print(df.info())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6P4KP46lweu",
        "outputId": "693c504a-b01f-40d2-9fd5-45b54aade368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17370913 entries, 0 to 17370912\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Dtype \n",
            "---  ------   ----- \n",
            " 0   year     int64 \n",
            " 1   title    object\n",
            " 2   excerpt  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 397.6+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Display the number of rows and columns\n",
        "print(f\"Number of rows: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "\n",
        "# Display the data types of each column\n",
        "print(df.dtypes)\n",
        "\n",
        "# Display the number of unique values in each column\n",
        "print(df.nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-gM7zqYl17s",
        "outputId": "5a97eaf7-ac58-4c52-b379-4be1dab16e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 17370913\n",
            "Number of columns: 3\n",
            "year        int64\n",
            "title      object\n",
            "excerpt    object\n",
            "dtype: object\n",
            "year            101\n",
            "title      10718164\n",
            "excerpt     5212707\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsZQ4lsij03v",
        "outputId": "91b6801d-4cf0-4043-af09-800ab7e3b072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17370913, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "earliest_year = df['year'].min()\n",
        "latest_year = df['year'].max()\n",
        "num_years = latest_year - earliest_year + 1\n",
        "\n",
        "print(f\"Earliest Year: {earliest_year}\")\n",
        "print(f\"Latest Year: {latest_year}\")\n",
        "print(f\"Number of Years: {num_years}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n15v0Z1-ked4",
        "outputId": "b5d437fd-b5b5-4368-872b-f6ad87ffa126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earliest Year: 1920\n",
            "Latest Year: 2020\n",
            "Number of Years: 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords only if necessary\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Preload stopwords to a set for faster access\n",
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSJ5GCaWv9yG",
        "outputId": "467ac9aa-6b08-4c5a-9042-e7caa17bea3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to standardize text\n",
        "def standardize_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove punctuation, numbers, and unwanted characters\n",
        "        # Keep only alphabets and spaces (remove everything else)\n",
        "        text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "        # Remove stop words (using set for fast lookup)\n",
        "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "        # Ensure there are no leading/trailing spaces\n",
        "        text = text.strip()\n",
        "\n",
        "        return text\n",
        "    return ''\n",
        "\n",
        "# Apply the standardization function to the 'title' and 'excerpt' columns separately, then combine\n",
        "df['standardized_title'] = df['title'].apply(standardize_text)\n",
        "df['standardized_excerpt'] = df['excerpt'].apply(standardize_text)\n",
        "df['standardized_text'] = df['standardized_title'] + ' ' + df['standardized_excerpt']\n",
        "\n",
        "# Now the DataFrame is ready with the standardized text\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "6WqUwIXQrbVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162e4cae-748d-4211-8f49-ec72cac6db20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year                                              title  \\\n",
            "0  1920  At last the Federal Reserve Board has issued r...   \n",
            "1  1920                            WILL TEST DOOR SERVICE.   \n",
            "2  1920                    Sanction for Chinese Contracts.   \n",
            "3  1920                            LEADS FRAZIER BY 4,496.   \n",
            "4  1920  CHICAGO, April 30.--With 300 suspicious charac...   \n",
            "\n",
            "                                             excerpt  \\\n",
            "0                                                      \n",
            "1  Service Board to Further Examine I.R.T. Safety...   \n",
            "2                                                      \n",
            "3  Langer's Margin Falls in North Dakota--Gronna ...   \n",
            "4  Federal Agents and Police Round-- up Suspiciou...   \n",
            "\n",
            "                                  standardized_title  \\\n",
            "0  last federal reserve board issued rules organi...   \n",
            "1                                  test door service   \n",
            "2                         sanction chinese contracts   \n",
            "3                                      leads frazier   \n",
            "4  chicago april suspicious characters including ...   \n",
            "\n",
            "                                standardized_excerpt  \\\n",
            "0                                                      \n",
            "1         service board examine irt safety invention   \n",
            "2                                                      \n",
            "3  langers margin falls north dakotagronna also a...   \n",
            "4  federal agents police round suspicious iwws co...   \n",
            "\n",
            "                                   standardized_text  \n",
            "0  last federal reserve board issued rules organi...  \n",
            "1  test door service service board examine irt sa...  \n",
            "2                        sanction chinese contracts   \n",
            "3  leads frazier langers margin falls north dakot...  \n",
            "4  chicago april suspicious characters including ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df\n"
      ],
      "metadata": {
        "id": "XCfa-g1-7JFl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "f1c09943-41f8-4768-8346-7a61ece0ccc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          year                                              title  \\\n",
              "0         1920  At last the Federal Reserve Board has issued r...   \n",
              "1         1920                            WILL TEST DOOR SERVICE.   \n",
              "2         1920                    Sanction for Chinese Contracts.   \n",
              "3         1920                            LEADS FRAZIER BY 4,496.   \n",
              "4         1920  CHICAGO, April 30.--With 300 suspicious charac...   \n",
              "...        ...                                                ...   \n",
              "17370908  2020  The pandemic has inspired a flurry of new and ...   \n",
              "17370909  2020  And what else you need to know today. Georgia’...   \n",
              "17370910  2020  In major global cities where the pandemic has ...   \n",
              "17370911  2020  Quotation of the Day for Sunday, August 2, 202...   \n",
              "17370912  2020  Mixed reaction to the news that Maj. Gen. Qass...   \n",
              "\n",
              "                                                    excerpt  \\\n",
              "0                                                             \n",
              "1         Service Board to Further Examine I.R.T. Safety...   \n",
              "2                                                             \n",
              "3         Langer's Margin Falls in North Dakota--Gronna ...   \n",
              "4         Federal Agents and Police Round-- up Suspiciou...   \n",
              "...                                                     ...   \n",
              "17370908                                                      \n",
              "17370909                                                      \n",
              "17370910                                                      \n",
              "17370911                                                      \n",
              "17370912                                                      \n",
              "\n",
              "                                         standardized_title  \\\n",
              "0         last federal reserve board issued rules organi...   \n",
              "1                                         test door service   \n",
              "2                                sanction chinese contracts   \n",
              "3                                             leads frazier   \n",
              "4         chicago april suspicious characters including ...   \n",
              "...                                                     ...   \n",
              "17370908  pandemic inspired flurry new novel items given...   \n",
              "17370909           else need know today georgias long lines   \n",
              "17370910  major global cities pandemic ebbed appears pub...   \n",
              "17370911  quotation day sunday august quotation day law ...   \n",
              "17370912  mixed reaction news maj gen qassim suleimani d...   \n",
              "\n",
              "                                       standardized_excerpt  \\\n",
              "0                                                             \n",
              "1                service board examine irt safety invention   \n",
              "2                                                             \n",
              "3         langers margin falls north dakotagronna also a...   \n",
              "4         federal agents police round suspicious iwws co...   \n",
              "...                                                     ...   \n",
              "17370908                                                      \n",
              "17370909                                                      \n",
              "17370910                                                      \n",
              "17370911                                                      \n",
              "17370912                                                      \n",
              "\n",
              "                                          standardized_text  \n",
              "0         last federal reserve board issued rules organi...  \n",
              "1         test door service service board examine irt sa...  \n",
              "2                               sanction chinese contracts   \n",
              "3         leads frazier langers margin falls north dakot...  \n",
              "4         chicago april suspicious characters including ...  \n",
              "...                                                     ...  \n",
              "17370908  pandemic inspired flurry new novel items given...  \n",
              "17370909          else need know today georgias long lines   \n",
              "17370910  major global cities pandemic ebbed appears pub...  \n",
              "17370911  quotation day sunday august quotation day law ...  \n",
              "17370912  mixed reaction news maj gen qassim suleimani d...  \n",
              "\n",
              "[17370913 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf97bb3f-bdb3-4df3-98cb-e3b45f1a3254\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>standardized_title</th>\n",
              "      <th>standardized_excerpt</th>\n",
              "      <th>standardized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1920</td>\n",
              "      <td>At last the Federal Reserve Board has issued r...</td>\n",
              "      <td></td>\n",
              "      <td>last federal reserve board issued rules organi...</td>\n",
              "      <td></td>\n",
              "      <td>last federal reserve board issued rules organi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1920</td>\n",
              "      <td>WILL TEST DOOR SERVICE.</td>\n",
              "      <td>Service Board to Further Examine I.R.T. Safety...</td>\n",
              "      <td>test door service</td>\n",
              "      <td>service board examine irt safety invention</td>\n",
              "      <td>test door service service board examine irt sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1920</td>\n",
              "      <td>Sanction for Chinese Contracts.</td>\n",
              "      <td></td>\n",
              "      <td>sanction chinese contracts</td>\n",
              "      <td></td>\n",
              "      <td>sanction chinese contracts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1920</td>\n",
              "      <td>LEADS FRAZIER BY 4,496.</td>\n",
              "      <td>Langer's Margin Falls in North Dakota--Gronna ...</td>\n",
              "      <td>leads frazier</td>\n",
              "      <td>langers margin falls north dakotagronna also a...</td>\n",
              "      <td>leads frazier langers margin falls north dakot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1920</td>\n",
              "      <td>CHICAGO, April 30.--With 300 suspicious charac...</td>\n",
              "      <td>Federal Agents and Police Round-- up Suspiciou...</td>\n",
              "      <td>chicago april suspicious characters including ...</td>\n",
              "      <td>federal agents police round suspicious iwws co...</td>\n",
              "      <td>chicago april suspicious characters including ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17370908</th>\n",
              "      <td>2020</td>\n",
              "      <td>The pandemic has inspired a flurry of new and ...</td>\n",
              "      <td></td>\n",
              "      <td>pandemic inspired flurry new novel items given...</td>\n",
              "      <td></td>\n",
              "      <td>pandemic inspired flurry new novel items given...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17370909</th>\n",
              "      <td>2020</td>\n",
              "      <td>And what else you need to know today. Georgia’...</td>\n",
              "      <td></td>\n",
              "      <td>else need know today georgias long lines</td>\n",
              "      <td></td>\n",
              "      <td>else need know today georgias long lines</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17370910</th>\n",
              "      <td>2020</td>\n",
              "      <td>In major global cities where the pandemic has ...</td>\n",
              "      <td></td>\n",
              "      <td>major global cities pandemic ebbed appears pub...</td>\n",
              "      <td></td>\n",
              "      <td>major global cities pandemic ebbed appears pub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17370911</th>\n",
              "      <td>2020</td>\n",
              "      <td>Quotation of the Day for Sunday, August 2, 202...</td>\n",
              "      <td></td>\n",
              "      <td>quotation day sunday august quotation day law ...</td>\n",
              "      <td></td>\n",
              "      <td>quotation day sunday august quotation day law ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17370912</th>\n",
              "      <td>2020</td>\n",
              "      <td>Mixed reaction to the news that Maj. Gen. Qass...</td>\n",
              "      <td></td>\n",
              "      <td>mixed reaction news maj gen qassim suleimani d...</td>\n",
              "      <td></td>\n",
              "      <td>mixed reaction news maj gen qassim suleimani d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17370913 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf97bb3f-bdb3-4df3-98cb-e3b45f1a3254')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf97bb3f-bdb3-4df3-98cb-e3b45f1a3254 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf97bb3f-bdb3-4df3-98cb-e3b45f1a3254');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e15ed377-06b1-480e-8724-ddb58cac3e0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e15ed377-06b1-480e-8724-ddb58cac3e0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e15ed377-06b1-480e-8724-ddb58cac3e0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e6978a79-b501-439e-8380-583d05c06b60\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e6978a79-b501-439e-8380-583d05c06b60 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Drop 'title' and 'excerpt' columns\n",
        "df = df.drop(['title', 'excerpt'], axis=1)\n",
        "\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "HNTFNK2sSuyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fb44e4-94c0-4d96-ebf5-32b506a87241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year                                 standardized_title  \\\n",
            "0  1920  last federal reserve board issued rules organi...   \n",
            "1  1920                                  test door service   \n",
            "2  1920                         sanction chinese contracts   \n",
            "3  1920                                      leads frazier   \n",
            "4  1920  chicago april suspicious characters including ...   \n",
            "\n",
            "                                standardized_excerpt  \\\n",
            "0                                                      \n",
            "1         service board examine irt safety invention   \n",
            "2                                                      \n",
            "3  langers margin falls north dakotagronna also a...   \n",
            "4  federal agents police round suspicious iwws co...   \n",
            "\n",
            "                                   standardized_text  \n",
            "0  last federal reserve board issued rules organi...  \n",
            "1  test door service service board examine irt sa...  \n",
            "2                        sanction chinese contracts   \n",
            "3  leads frazier langers margin falls north dakot...  \n",
            "4  chicago april suspicious characters including ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Save the processed DataFrame to a new Parquet file in Google Drive\n",
        "df.to_parquet('/content/drive/MyDrive/processed_nyt_data.parquet')"
      ],
      "metadata": {
        "id": "ME0HHjOu-pbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323ab690-9cb5-4cdc-a3dc-b67bed184361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year                                 standardized_title  \\\n",
            "0  1920  last federal reserve board issued rules organi...   \n",
            "1  1920                                  test door service   \n",
            "2  1920                         sanction chinese contracts   \n",
            "3  1920                                      leads frazier   \n",
            "4  1920  chicago april suspicious characters including ...   \n",
            "\n",
            "                                standardized_excerpt  \\\n",
            "0                                                      \n",
            "1         service board examine irt safety invention   \n",
            "2                                                      \n",
            "3  langers margin falls north dakotagronna also a...   \n",
            "4  federal agents police round suspicious iwws co...   \n",
            "\n",
            "                                   standardized_text  \n",
            "0  last federal reserve board issued rules organi...  \n",
            "1  test door service service board examine irt sa...  \n",
            "2                        sanction chinese contracts   \n",
            "3  leads frazier langers margin falls north dakot...  \n",
            "4  chicago april suspicious characters including ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "1d9tu1u8n7CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sampling 50% or 10% of the data to speed up the process\n",
        "sample_df = df.sample(frac=0.1, random_state=42)  # 10% sample\n",
        "print(sample_df)\n",
        "\n",
        "# Create an instance of TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Use the sampled data for TF-IDF vectorization\n",
        "tfidf_matrix = vectorizer.fit_transform(sample_df['standardized_text']) # Call fit_transform on the instance"
      ],
      "metadata": {
        "id": "RbLgNgSrnsBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451bed60-c8f9-4a5a-e36b-eb4424041ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          year                                 standardized_title  \\\n",
            "871974    1927          schooner morrissey receives food supplies   \n",
            "3563372   1938     tenanted repairs new housing sped indianapolis   \n",
            "11774055  1982  edwin h mosler jr former president chief execu...   \n",
            "11142793  1975  reprs procommunist trade unions neighborhood c...   \n",
            "10942590  1974  bill virdons first season manager pirates team...   \n",
            "...        ...                                                ...   \n",
            "3558555   1938  wash suburban sanitary dist md financing activ...   \n",
            "9829470   1966  british state mind insists upon rejection feel...   \n",
            "11486971  1978              article popularity rare tiffany glass   \n",
            "6323141   1950                                    equitable lends   \n",
            "4934695   1944  takeout double used nearly thirty years strong...   \n",
            "\n",
            "                                       standardized_excerpt  \\\n",
            "871974    sail rye june plans personnel b putnam nusbaum...   \n",
            "3563372   straus says project held investigation tenante...   \n",
            "11774055                                                      \n",
            "11142793  rally presided gen eurico jesus deus corvacho ...   \n",
            "10942590  lost record majors tired following september s...   \n",
            "...                                                     ...   \n",
            "3558555         new bond note issues offered bankers public   \n",
            "9829470                                                       \n",
            "11486971  notes met museum art incorporate loggia louis ...   \n",
            "6323141                                                       \n",
            "4934695                                                       \n",
            "\n",
            "                                          standardized_text  \n",
            "871974    schooner morrissey receives food supplies sail...  \n",
            "3563372   tenanted repairs new housing sped indianapolis...  \n",
            "11774055  edwin h mosler jr former president chief execu...  \n",
            "11142793  reprs procommunist trade unions neighborhood c...  \n",
            "10942590  bill virdons first season manager pirates team...  \n",
            "...                                                     ...  \n",
            "3558555   wash suburban sanitary dist md financing activ...  \n",
            "9829470   british state mind insists upon rejection feel...  \n",
            "11486971  article popularity rare tiffany glass notes me...  \n",
            "6323141                                    equitable lends   \n",
            "4934695   takeout double used nearly thirty years strong...  \n",
            "\n",
            "[1737091 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the number of features further for faster computation\n",
        "# The n_jobs parameter is not available within the __init__ for older versions of scikit-learn.\n",
        "# Remove it here, or upgrade scikit-learn.\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 1))  # 500 features\n",
        "\n",
        "# Fit and transform the sampled data\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['standardized_text'])"
      ],
      "metadata": {
        "id": "GnvU1PQDnt7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "# Download VADER lexicon if not already downloaded\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "# Initialize SentimentIntensityAnalyzer once\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to determine sentiment from the compound score\n",
        "def get_sentiment(text):\n",
        "    score = sia.polarity_scores(text)\n",
        "    if score['compound'] >= 0.05:\n",
        "        return 'positive'\n",
        "    elif score['compound'] <= -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Function to process each chunk and apply sentiment analysis\n",
        "def process_chunk(chunk):\n",
        "    chunk['sentiment'] = chunk['standardized_text'].apply(get_sentiment)\n",
        "    return chunk\n",
        "\n",
        "# Path to the input and output Parquet files\n",
        "input_file = '/content/drive/MyDrive/processed_nyt_data.parquet'\n",
        "output_file = '/content/drive/MyDrive/sentiment_analysis_result.parquet'\n",
        "\n",
        "# Open the Parquet file using pyarrow for reading\n",
        "parquet_file = pq.ParquetFile(input_file)\n",
        "\n",
        "# Create the output ParquetWriter for appending\n",
        "first_chunk = True  # Flag to handle writing the schema only once\n",
        "\n",
        "# Initialize ProcessPoolExecutor for parallel processing\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    futures = []\n",
        "    for i in range(parquet_file.num_row_groups):\n",
        "        # Read a chunk of data from the Parquet file\n",
        "        df_chunk = parquet_file.read_row_group(i).to_pandas()\n",
        "\n",
        "        # Process data in smaller parts (split into smaller chunks if needed)\n",
        "        chunk_size = 50000  # Size of each chunk to process (adjust as needed)\n",
        "        for start in range(0, len(df_chunk), chunk_size):\n",
        "            end = min(start + chunk_size, len(df_chunk))\n",
        "            chunk = df_chunk.iloc[start:end]\n",
        "\n",
        "            # Submit chunk processing to the executor\n",
        "            futures.append(executor.submit(process_chunk, chunk))\n",
        "\n",
        "    # Collect results as they finish and write to Parquet directly (streaming)\n",
        "    for future in futures:\n",
        "        result_chunk = future.result()\n",
        "\n",
        "        # Open the ParquetWriter once and write the first chunk with schema\n",
        "        if first_chunk:\n",
        "            # Write the first chunk with the schema (mode 'w')\n",
        "            result_chunk.to_parquet(output_file, index=False, mode='w')\n",
        "            first_chunk = False\n",
        "        else:\n",
        "            # For subsequent chunks, append the data (mode 'a')\n",
        "            result_chunk.to_parquet(output_file, index=False, mode='a')\n",
        "\n",
        "print(f\"Sentiment analysis complete. Results saved to {output_file}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "uuJbcK01pzDx",
        "outputId": "c943f78a-1bd2-4f3e-aaf9-0eac23582200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "__cinit__() got an unexpected keyword argument 'mode'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-cdb0e555e147>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfirst_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Write the first chunk with the schema (mode 'w')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mresult_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mfirst_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   3111\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3113\u001b[0;31m         return to_parquet(\n\u001b[0m\u001b[1;32m   3114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFilePath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mWriteBuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     impl.write(\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;31m# write to single output file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 self.api.parquet.write_table(\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mwrite_table\u001b[0;34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, column_encoding, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, write_page_index, write_page_checksum, sorting_columns, store_decimal_as_integer, **kwargs)\u001b[0m\n\u001b[1;32m   1900\u001b[0m     \u001b[0muse_int96\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_deprecated_int96_timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m         with ParquetWriter(\n\u001b[0m\u001b[1;32m   1903\u001b[0m                 \u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                 \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, where, schema, filesystem, flavor, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, compression_level, use_byte_stream_split, column_encoding, writer_engine_version, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, write_page_index, write_page_checksum, sorting_columns, store_decimal_as_integer, **options)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_collector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata_collector'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0mengine_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'V2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         self.writer = _parquet.ParquetWriter(\n\u001b[0m\u001b[1;32m   1022\u001b[0m             \u001b[0msink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/_parquet.pyx\u001b[0m in \u001b[0;36mpyarrow._parquet.ParquetWriter.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __cinit__() got an unexpected keyword argument 'mode'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Latent Dirichlet Allocation** (LDA), a popular topic modeling technique."
      ],
      "metadata": {
        "id": "6SnWCP_iAZ_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Create a dictionary from the tokenized texts (list of lists of words)\n",
        "dictionary = corpora.Dictionary(tokenized_texts)\n",
        "\n",
        "# Create a corpus (bag-of-words) representation for each document\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
        "\n",
        "# Train the LDA model with the corpus and dictionary, specifying the number of topics\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)\n"
      ],
      "metadata": {
        "id": "Q_UgmBLY8y9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the top 10 words for each topic\n",
        "for idx, topic in lda_model.print_topics(num_topics=10, num_words=10):\n",
        "    print(f\"Topic #{idx + 1}: {topic}\")\n"
      ],
      "metadata": {
        "id": "EF4tX2Uz9hqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NMF**\n",
        "\n",
        "(Non-negative Matrix Factorization)\n"
      ],
      "metadata": {
        "id": "H7p5gT3a_-w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Initialize the NMF model with 10 components (topics)\n",
        "nmf_model = NMF(n_components=10, random_state=42)\n",
        "\n",
        "# Fit the NMF model to the TF-IDF matrix and transform the data\n",
        "nmf_output = nmf_model.fit_transform(tfidf_matrix)\n"
      ],
      "metadata": {
        "id": "T5iF10Pz8_fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 10 words for each topic\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "for topic_idx, topic in enumerate(nmf_model.components_):\n",
        "    top_words_idx = topic.argsort()[-10:][::-1]  # Get the indices of the top 10 words for the topic\n",
        "    top_words = [feature_names[i] for i in top_words_idx]\n",
        "    print(f\"Topic #{topic_idx + 1}: {' '.join(top_words)}\")\n"
      ],
      "metadata": {
        "id": "OuCoHtSL9UT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERTopic**\n",
        "\n",
        "BERTopic, a popular topic modeling library that leverages transformer-based embeddings (like BERT) to extract topics from text.\n",
        "\n"
      ],
      "metadata": {
        "id": "OTDBpjum_kWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# Initialize the BERTopic model\n",
        "bertopic_model = BERTopic(language=\"english\", calculate_probabilities=True)\n",
        "\n",
        "# Fit the model to the cleaned text data and transform it into topics\n",
        "topics, _ = bertopic_model.fit_transform(df['cleaned_text'])\n"
      ],
      "metadata": {
        "id": "XjF0MQOK9mpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# Initialize the BERTopic model\n",
        "bertopic_model = BERTopic(language=\"english\", calculate_probabilities=True)\n",
        "\n",
        "# Fit the model to the cleaned text data and transform it into topics\n",
        "topics, _ = bertopic_model.fit_transform(df['cleaned_text'])\n"
      ],
      "metadata": {
        "id": "JXIMvzZ899Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Coherence Score for LDA:**"
      ],
      "metadata": {
        "id": "qwe-e_iG_fd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Initialize the CoherenceModel with the LDA model, tokenized texts, and the dictionary\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
        "\n",
        "# Calculate the coherence score\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n"
      ],
      "metadata": {
        "id": "0UYyjUAm-JbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have trained multiple LDA models with different parameters:\n",
        "coherence_model_lda_1 = CoherenceModel(model=lda_model_1, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda_1 = coherence_model_lda_1.get_coherence()\n",
        "\n",
        "coherence_model_lda_2 = CoherenceModel(model=lda_model_2, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda_2 = coherence_model_lda_2.get_coherence()\n",
        "\n",
        "print(f\"Coherence Score for Model 1: {coherence_lda_1}\")\n",
        "print(f\"Coherence Score for Model 2: {coherence_lda_2}\")\n"
      ],
      "metadata": {
        "id": "arxWynoj-WB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silhouette Score for NMF:\n",
        "**bold text**"
      ],
      "metadata": {
        "id": "Y3Uw0WeJ_W_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Calculate the Silhouette Score for the NMF model\n",
        "silhouette_avg = silhouette_score(tfidf_matrix, nmf_output.argmax(axis=1))\n"
      ],
      "metadata": {
        "id": "nxEniYgh-b_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Define the range of number of topics\n",
        "topic_range = [5, 10, 15, 20, 25]\n",
        "\n",
        "silhouette_scores = []\n",
        "\n",
        "for n_topics in topic_range:\n",
        "    # Fit the NMF model with the current number of topics\n",
        "    nmf_model = NMF(n_components=n_topics, random_state=42)\n",
        "    nmf_output = nmf_model.fit_transform(tfidf_matrix)\n",
        "\n",
        "    # Calculate the silhouette score\n",
        "    score = silhouette_score(tfidf_matrix, nmf_output.argmax(axis=1))\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "# Print the silhouette scores for each number of topics\n",
        "for n_topics, score in zip(topic_range, silhouette_scores):\n",
        "    print(f\"Silhouette Score for {n_topics} topics: {score}\")\n"
      ],
      "metadata": {
        "id": "9Ld_VqbG-sDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time-Based Analysis**\n",
        "Using the 'year' column for trend analysis:"
      ],
      "metadata": {
        "id": "seK6T2oH-8H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_topic_distribution = df.groupby('year')['cleaned_text'].apply(' '.join).reset_index()\n",
        "\n",
        "for year in yearly_topic_distribution['year'].unique():\n",
        "    # Get the text for the specific year\n",
        "    year_text = yearly_topic_distribution[yearly_topic_distribution['year'] == year]['cleaned_text'].values[0]\n",
        "\n",
        "    # Get the topic distribution for the year using the LDA model\n",
        "    year_topics = lda_model.get_document_topics(dictionary.doc2bow(year_text.split()))\n",
        "\n",
        "    print(f\"Top topics for year {year}:\")\n",
        "\n",
        "    # Sort topics by their probability and print the top 3 topics for the year\n",
        "    for topic_id, prob in sorted(year_topics, key=lambda x: x[1], reverse=True)[:3]:\n",
        "        print(f\"Topic {topic_id}: {lda_model.print_topic(topic_id, topn=5)}\")\n"
      ],
      "metadata": {
        "id": "KgWTNt1n-uME"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}